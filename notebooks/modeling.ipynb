{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "In this notebook, we'll be modeling the data we've previously prepared. Out notebook will be laid out as follows:\n",
    "\n",
    "1. Model Selection & Generation\n",
    "2. Hyperparameter Optimization\n",
    "3. Fine-Tuning (if needed)\n",
    "4. Reporting Best Model(s) + Settings\n",
    "5. Interpretation\n",
    "6. Conclusion\n",
    "\n",
    "Our eventual goal here is two-fold:\n",
    "\n",
    "1. Accurately [and fairly] model the diabetes dataset\n",
    "2. Interpret the results to find something worth recommending to those wanting to reduce risk of diabetes. This can be via LIME/SHAP (i.e. some interpretable model that approximates the neural network) or via analyzing a more simple model's structure (i.e. regression coefficients, random forest decision boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "from utils.model import *\n",
    "from utils.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Model Selection & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Train-Test Split Report>\n",
      "Train: 512886 obs, 170962 no diabetes [0], 170962 pre-diabetes [1], 170962 diabetes [2]\n",
      "Test: 50736 obs, 42741 no diabetes [0], 926 pre-diabetes [1], 7069 diabetes [2]\n",
      "[0 0 0 ... 2 0 0]\n",
      "\n",
      "<Test Report>\n",
      "Precision: [no diabetes] 0.8576161666049307, [pre-diabetes] 0.07242339832869081, [diabetes] 0.47055524397083565\n",
      "Recall: [no diabetes] 0.975059076764699, [pre-diabetes] 0.028077753779697623, [diabetes] 0.11868722591597114\n",
      "F1-Score: [no diabetes] 0.9125745880549625, [pre-diabetes] 0.04046692607003891, [diabetes] 0.1895616809760506\n",
      "Support: [no diabetes] 42741, [pre-diabetes] 926, [diabetes] 7069\n",
      "Accuracy: 83.8458%\n"
     ]
    }
   ],
   "source": [
    "# generate lookup for models\n",
    "models = {\n",
    "    # \"tree\": TreeClassifier(target=\"diabetes\", path=\"../datasets/pre_split_processed.parquet\"),\n",
    "    \"ffnn\": MLPClassifier(target=\"diabetes\", path=\"../datasets/pre_split_processed.parquet\")\n",
    "}\n",
    "\n",
    "# manual search\n",
    "models[\"ffnn\"].set_hyperparams({\n",
    "    \"learning_rate\": .0005,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_hidden\": 2,\n",
    "    \"hidden_size\": 2048,\n",
    "    \"num_epochs\": 50,\n",
    "    \"classify_fn\": \"sigmoid\"\n",
    "})\n",
    "\n",
    "# train & test basic model\n",
    "for mt, model in models.items():\n",
    "    # attempt to load, else train and test\n",
    "    if not model.load_model():\n",
    "        model.train_model(verbose=1)\n",
    "    model.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Grid-Search>\n",
      "Testing 7 combinations WITHOUT cross-validation\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# optimize hyperparams\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer_results \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(optimizer_results)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# optimize hyperparams\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer_results \u001b[38;5;241m=\u001b[39m {model_type: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model_type, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(optimizer_results)\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/model.py:880\u001b[0m, in \u001b[0;36mMLPClassifier.optimize_hyperparams\u001b[0;34m(self, grid_search, kfold)\u001b[0m\n\u001b[1;32m    877\u001b[0m max_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hyperparam_combo \u001b[38;5;129;01min\u001b[39;00m hyperparam_combos:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;66;03m# unpack\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m     hyperparam_combo \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mhyperparam_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparam_combo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhyperparam_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# train & test\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     cur_model \u001b[38;5;241m=\u001b[39m LinearNN(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparam_combo)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/model.py:880\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    877\u001b[0m max_perf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hyperparam_combo \u001b[38;5;129;01min\u001b[39;00m hyperparam_combos:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;66;03m# unpack\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m     hyperparam_combo \u001b[38;5;241m=\u001b[39m {hyperparam_list[i]: \u001b[43mhyperparam_combo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hyperparam_list))}\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# train & test\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     cur_model \u001b[38;5;241m=\u001b[39m LinearNN(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparam_combo)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# optimize hyperparams\n",
    "optimizer_results = {model_type: model.optimize_hyperparams(kfold=2) for model_type, model in models.items()}\n",
    "print(optimizer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Fine-Tuning + Other Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Best Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
