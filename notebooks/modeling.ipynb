{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "In this notebook, we'll be modeling the data we've previously prepared. Out notebook will be laid out as follows:\n",
    "\n",
    "1. Model Selection & Generation\n",
    "2. Hyperparameter Optimization\n",
    "3. Fine-Tuning (if needed)\n",
    "4. Reporting Best Model(s) + Settings\n",
    "5. Interpretation\n",
    "6. Conclusion\n",
    "\n",
    "Our eventual goal here is two-fold:\n",
    "\n",
    "1. Accurately [and fairly] model the diabetes dataset\n",
    "2. Interpret the results to find something worth recommending to those wanting to reduce risk of diabetes. This can be via LIME/SHAP (i.e. some interpretable model that approximates the neural network) or via analyzing a more simple model's structure (i.e. regression coefficients, random forest decision boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "from utils.model import *\n",
    "from utils.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Model Selection & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dtype Inference>\n",
      "diabetes\n",
      "high_bp\n",
      "high_chol\n",
      "chol_check\n",
      "bmi\n",
      "smoker\n",
      "stroke\n",
      "heart_disease\n",
      "physical_activity\n",
      "fruits\n",
      "veggies\n",
      "heavy_drinker\n",
      "healthcare\n",
      "no_doc_bc_cost\n",
      "general_health\n",
      "mental_health\n",
      "physical_health\n",
      "diff_walk\n",
      "sex\n",
      "age\n",
      "education\n",
      "income\n",
      "\t3 numeric vars, 0 nominal vars, 0 ordinal vars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SMOTE-NC is not designed to work only with numerical features. It requires some categorical features.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# generate lookup for models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# \"tree\": TreeClassifier(target=\"diabetes\", path=\"../datasets/pre_split_processed.parquet\"),\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffnn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mMLPClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiabetes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/pre_split_processed.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# manual search\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# models[\"tree\"].set_hyperparams({\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     \"loss\": \"log_loss\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     \"classify_fn\": \"sigmoid\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# })\u001b[39;00m\n\u001b[1;32m     29\u001b[0m models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffnn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mset_hyperparams({\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m.001\u001b[39m,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m })\n",
      "File \u001b[0;32m<string>:18\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, target, path, hyperparams, data, model, model_lookup_path, optimizer, loss_fn, device, scheduler, X_train, y_train, X_test, y_test, score)\u001b[0m\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/model.py:598\u001b[0m, in \u001b[0;36mMLPClassifier.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_hyperparams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparams, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/model.py:585\u001b[0m, in \u001b[0;36mMLPClassifier.gen_split\u001b[0;34m(self, test_prop)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget),\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m    582\u001b[0m )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# make augmentations\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m \u001b[43mpost_split_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# report\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Train-Test Split Report>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/wrappers.py:44\u001b[0m, in \u001b[0;36mpost_split_pipeline\u001b[0;34m(X_train, X_test, y_train, y_test, target, features, categorical_features)\u001b[0m\n\u001b[1;32m     42\u001b[0m X_train \u001b[38;5;241m=\u001b[39m normalize_features(X_train, features\u001b[38;5;241m=\u001b[39mfeatures)\n\u001b[1;32m     43\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train, y_train], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mup_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# normalize test\u001b[39;00m\n\u001b[1;32m     47\u001b[0m X_test \u001b[38;5;241m=\u001b[39m normalize_features(X_test, features\u001b[38;5;241m=\u001b[39mfeatures)\n",
      "File \u001b[0;32m~/ucdavis-courses/ecs-171/project/notebooks/utils/transform_dataset.py:136\u001b[0m, in \u001b[0;36mup_sampling\u001b[0;34m(df, target, categorical_features)\u001b[0m\n\u001b[1;32m    133\u001b[0m     categorical_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTENC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, categorical_features\u001b[38;5;241m=\u001b[39mcategorical_features)\n\u001b[0;32m--> 136\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m df_new \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_res, y_res], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdict\u001b[39m(y_res\u001b[38;5;241m.\u001b[39mvalue_counts()))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:647\u001b[0m, in \u001b[0;36mSMOTENC._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_ \u001b[38;5;241m=\u001b[39m _num_features(X)\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_types(X)\n\u001b[0;32m--> 647\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m X_continuous \u001b[38;5;241m=\u001b[39m _safe_indexing(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_features_, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    650\u001b[0m X_continuous \u001b[38;5;241m=\u001b[39m check_array(X_continuous, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:630\u001b[0m, in \u001b[0;36mSMOTENC._validate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE-NC is not designed to work only with categorical \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures. It requires some numerical features.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE-NC is not designed to work only with numerical \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures. It requires some categorical features.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: SMOTE-NC is not designed to work only with numerical features. It requires some categorical features."
     ]
    }
   ],
   "source": [
    "# generate lookup for models\n",
    "models = {\n",
    "    # \"tree\": TreeClassifier(target=\"diabetes\", path=\"../datasets/pre_split_processed.parquet\"),\n",
    "    \"ffnn\": MLPClassifier(target=\"diabetes\", path=\"../datasets/pre_split_processed.parquet\")\n",
    "}\n",
    "\n",
    "# manual search\n",
    "# models[\"tree\"].set_hyperparams({\n",
    "#     \"loss\": \"log_loss\",\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"n_estimators\": 100,\n",
    "#     \"criterion\": \"friedman_mse\",\n",
    "#     \"min_samples_split\": 2,\n",
    "#     \"min_samples_leaf\": 5,\n",
    "#     \"max_depth\": 3,\n",
    "#     \"n_iter_no_change\": 5,\n",
    "#     \"max_features\": \"log2\",\n",
    "#     \"tol\": 1e-4\n",
    "# })\n",
    "# models[\"ffnn\"].set_hyperparams({\n",
    "#     \"learning_rate\": .0005,\n",
    "#     \"batch_size\": 256,\n",
    "#     \"num_hidden\": 8,\n",
    "#     \"hidden_size\": [2048, 1024, 512, 256, 128, 64, 32, 32],\n",
    "#     \"num_epochs\": 50,\n",
    "#     \"dropout_rate\": [0.875, 0.75, 0.75, 0.5, 0.5, 0.25, 0.25],\n",
    "#     \"classify_fn\": \"sigmoid\"\n",
    "# })\n",
    "models[\"ffnn\"].set_hyperparams({\n",
    "    \"learning_rate\": .001,\n",
    "    \"batch_size\": 256,\n",
    "    \"num_hidden\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_epochs\": 50,\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"classify_fn\": \"softmax\"\n",
    "})\n",
    "\n",
    "# train & test basic model\n",
    "for mt, model in models.items():\n",
    "    # attempt to load, else train and test\n",
    "    # if not model.load_model():\n",
    "    model.train_model(verbose=2)\n",
    "    model.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize hyperparams\n",
    "# optimizer_results = {model_type: model.optimize_hyperparams(kfold=2) for model_type, model in models.items()}\n",
    "# print(optimizer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Fine-Tuning + Other Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Best Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
